# LLM Failure Analyzer for RAG Systems

This project is a diagnostic toolkit for analyzing failure modes in Retrieval-Augmented Generation (RAG) pipelines.

Instead of generating answers, the system inspects RAG outputs to identify:
- hallucinations
- weak grounding
- retrieval failures

It is designed as an internal tool for AI engineers to understand *why* a RAG system fails.

